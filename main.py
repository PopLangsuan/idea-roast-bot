import os
import sys
import threading
import json
import re
import requests
import concurrent.futures
from datetime import datetime
from dotenv import load_dotenv
from fastapi import FastAPI, Request, HTTPException
from fastapi.staticfiles import StaticFiles
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
# 1. [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç] ‡πÄ‡∏û‡∏¥‡πà‡∏° ImageMessage ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
from linebot.models import MessageEvent, TextMessage, TextSendMessage, ImageMessage

# 1. ‡πÇ‡∏´‡∏•‡∏î Config
load_dotenv()
line_token = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')
line_secret = os.getenv('LINE_CHANNEL_SECRET')
gemini_key = os.getenv('GEMINI_API_KEY')
notion_key = os.getenv('NOTION_API_KEY')
notion_db_id = os.getenv('NOTION_DATABASE_ID')
NGROK_URL = "https://keiko-motivational-insuperably.ngrok-free.dev" # üëâ ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÅ‡∏Å‡πâ!

if not all([line_token, line_secret, gemini_key, notion_key, notion_db_id]):
    sys.exit(1)

# 2. Setup Models (‡πÉ‡∏ä‡πâ Lite ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
genai.configure(api_key=gemini_key)
# ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: gemini-flash-latest ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
chat_model = genai.GenerativeModel("gemini-flash-latest") 

safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

headers = {"Authorization": f"Bearer {notion_key}", "Content-Type": "application/json", "Notion-Version": "2022-06-28"}

# --- Helper Functions (Notion) ---

def fetch_keyword_search(user_msg, user_id):
    """‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Keyword (Timeout ‡∏™‡∏±‡πâ‡∏ô)"""
    url = f"https://api.notion.com/v1/databases/{notion_db_id}/query"
    payload = {
        "filter": {
            "and": [
                {"property": "Idea", "rich_text": {"contains": user_msg}},
                {"property": "UserID", "rich_text": {"equals": user_id}}
            ]
        },
        "page_size": 1
    }
    try:
        # ‚ö° Timeout ‡πÅ‡∏Ñ‡πà 1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏°‡∏≤‡∏ä‡πâ‡∏≤‡∏ï‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á)
        response = requests.post(url, json=payload, headers=headers, timeout=1.5) 
        results = response.json().get("results", [])
        if results:
            item = results[0]['properties']
            return f"‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏£‡∏á‡∏à‡∏≥: ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏Ñ‡∏¢‡∏û‡∏π‡∏î‡∏ß‡πà‡∏≤ '{item['Idea']['title'][0]['text']['content']}' ‡πÅ‡∏•‡∏∞‡∏â‡∏±‡∏ô‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ '{item['Feedback']['rich_text'][0]['text']['content']}'"
    except: pass
    return None

def fetch_recent_chat(user_id):
    """‡∏î‡∏∂‡∏á‡πÅ‡∏ä‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (Timeout ‡∏™‡∏±‡πâ‡∏ô)"""
    url = f"https://api.notion.com/v1/databases/{notion_db_id}/query"
    payload = {
        "filter": {"property": "UserID", "rich_text": {"equals": user_id}},
        "sorts": [{"property": "Date", "direction": "descending"}],
        "page_size": 1
    }
    try:
        # ‚ö° Timeout ‡πÅ‡∏Ñ‡πà 1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
        response = requests.post(url, json=payload, headers=headers, timeout=1.5)
        results = response.json().get("results", [])
        if results:
            item = results[0]['properties']
            return f"‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: ‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á '{item['Idea']['title'][0]['text']['content']}' ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ '{item['Feedback']['rich_text'][0]['text']['content']}'"
    except: pass
    return None

def get_smart_memory_fast(user_msg, user_id):
    """
    üèéÔ∏è ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÅ‡∏ö‡∏ö Speed-First:
    ‡πÉ‡∏´‡πâ‡πÄ‡∏ß‡∏•‡∏≤ Notion ‡πÅ‡∏Ñ‡πà 1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ó‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡πá‡∏ß‡∏Å‡πà‡∏≠‡∏ô
    """
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_keyword = executor.submit(fetch_keyword_search, user_msg, user_id)
        future_recent = executor.submit(fetch_recent_chat, user_id)

        try:
            # ‡∏£‡∏≠‡πÅ‡∏Ñ‡πà 1.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô! (‡∏•‡∏î‡∏à‡∏≤‡∏Å 4)
            keyword_result = future_keyword.result(timeout=1.5)
            recent_result = future_recent.result(timeout=1.5)
            
            if keyword_result: return keyword_result
            if recent_result: return recent_result
        except concurrent.futures.TimeoutError:
            print("‚ö†Ô∏è Memory Timeout: Notion ‡∏ä‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡∏Ç‡πâ‡∏≤‡∏°!")
        except Exception as e:
            print(f"Memory Error: {e}")

    return "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ô‡πâ‡∏ô‡∏ï‡∏≠‡∏ö‡πÄ‡∏£‡πá‡∏ß)"

def save_to_notion(user_idea, ai_reply, user_id, category):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Background"""
    print(f"üíæ Background Save: {category}")
    url = "https://api.notion.com/v1/pages"
    payload = {
        "parent": {"database_id": notion_db_id},
        "properties": {
            "Idea": {"title": [{"text": {"content": user_idea}}]},
            "Feedback": {"rich_text": [{"text": {"content": ai_reply[:2000]}}]},
            "UserID": {"rich_text": [{"text": {"content": user_id}}]},
            "Category": {"select": {"name": category}}, 
            "Date": {"date": {"start": datetime.now().isoformat()}}
        }
    }
    try: requests.post(url, json=payload, headers=headers)
    except: pass

def clean_json_string(json_str):
    cleaned = re.sub(r'```json\s*', '', json_str)
    cleaned = re.sub(r'```', '', cleaned)
    return cleaned.strip()

# --- System Prompt (‡∏≠‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏•‡∏π‡∏Å‡∏û‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß) ---
SYSTEM_PROMPT = """
Role: You are "IdeaPartner", a sincere and supportive business partner (Friendly & Witty).
Mindset: Based on Dale Carnegie + Positive Psychology:
1. Show genuine interest in the user.
2. Be a good listener & Show empathy.
3. Don't judge, just support.
4. Growth Mindset.

rules_language:
**CRITICAL:** Detect the user's input language and respond in the **SAME** language.

Mode 1: If User speaks THAI üáπüá≠
- Tone: "Modern Thai Friend 2024" (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏™‡∏ô‡∏¥‡∏ó‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢)
- Style: Casual, fun, sincere, use Thai particles (e.g., ‡∏ß‡πà‡∏∞, ‡πÄ‡∏ô‡∏≠‡∏∞, ‡∏™‡∏¥, ‡πÄ‡∏ß‡πâ‡∏¢).
- No translationese: Use natural Thai slang.

Mode 2: If User speaks ENGLISH üá∫üá∏
- Tone: "Friendly American Creator/Founder"
- Style: Casual, energetic, concise. Use words like "Dude", "Man", "Gotcha", "Totally".
- No textbook English: Make it sound natural and spoken.

General Rules (For both languages):
1. **Length:** Short & Punchy! (Max 3-4 lines).
2. **Business/Productivity:** Praise first (Dale Carnegie) -> Then ask a thought-provoking question.
3. **Self-Dev (Sad/Burnout):** Empathy first! Comfort them. No teaching.
4. **Off-topic:** Politely decline in a friendly way.
5. **Memory:**
   - If [Memory] says "Past/History": Greet them like an old friend ("Hey! I remember you wanted to sell...")
   - If [Memory] says "Recent/Context": Continue the conversation smoothly.

Output Format (JSON Only):
{
  "category": "Choose from: Business / Productivity / Self-Dev / Off-topic / Finance",
  "reply": "Your response string (in the detected language)"
}
"""

app = FastAPI()
# ‡πÅ‡∏ó‡∏£‡∏Å‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Å‡πà‡∏≠‡∏ô app.mount
if not os.path.exists("static"):
    os.makedirs("static")
app.mount("/static", StaticFiles(directory="static"), name="static")
line_bot_api = LineBotApi(line_token)
handler = WebhookHandler(line_secret)

@app.get("/")
async def root(): return {"status": "Active", "mode": "Speed King (1.5s Timeout) + Vision Ready"}

@app.post("/callback")
async def callback(request: Request):
    signature = request.headers.get('X-Line-Signature', '')
    body = await request.body()
    try: handler.handle(body.decode('utf-8'), signature)
    except InvalidSignatureError: raise HTTPException(status_code=400)
    return 'OK'

# ---------------------------------------------------------
# ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏î‡∏¥‡∏°: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (Text)
# ---------------------------------------------------------
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_msg = event.message.text
    user_id = event.source.user_id
    reply_token = event.reply_token
    
    try:
        # 1. Parallel Memory Fetch (Timeout 1.5s)
        memory_context = get_smart_memory_fast(user_msg, user_id)
        
        # 2. Gemini Thinking
        full_prompt = f"{SYSTEM_PROMPT}\n\n[Memory]\n{memory_context}\n\n[Input]\n{user_msg}\n\nResponse (JSON):"
        
        response = chat_model.generate_content(
            full_prompt, 
            safety_settings=safety_settings
        )
        
        raw_reply = response.text.strip()
        print(f"ü§ñ AI (Text): {raw_reply[:30]}...") 

        # 3. Clean JSON
        try:
            cleaned_json = clean_json_string(raw_reply)
            data = json.loads(cleaned_json)
            category = data.get("category", "General") 
            ai_reply = data.get("reply", "‡πÇ‡∏ó‡∏©‡∏ó‡∏µ ‡πÄ‡∏ö‡∏•‡∏≠‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢ ‡πÄ‡∏≠‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞")
        except:
            category = "General"
            ai_reply = raw_reply

        # 4. ‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!
        line_bot_api.reply_message(reply_token, TextSendMessage(text=ai_reply))
        
        # 5. Save Background
        if category != "Off-topic":
            bg_thread = threading.Thread(
                target=save_to_notion, 
                args=(user_msg, ai_reply, user_id, category)
            )
            bg_thread.start()

    except Exception as e:
        print(f"Error: {e}")

# ---------------------------------------------------------
# [‡πÉ‡∏´‡∏°‡πà] ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (Image) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏ß‡∏î!
# ---------------------------------------------------------
@handler.add(MessageEvent, message=ImageMessage)
def handle_image_message(event):
    reply_token = event.reply_token
    try:
        print("üì∏ Received Image...")
        
        # 1. ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å LINE Server
        message_content = line_bot_api.get_message_content(event.message.id)
        image_bytes = message_content.content
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vision ‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        vision_prompt = """
        Role: You are "IdeaPartner" (AI Life Coach).
        Task: Analyze this image and respond based on context:
        
        Scenario A: If it's a messy room/desk:
        - Tease them gently (friendly joke).
        - Suggest 1 tiny step to organize (e.g., "Move that coffee cup first").
        
        Scenario B: If it's a notebook/handwriting/bills:
        - Analyze the numbers or content briefly.
        - Compliment their discipline in tracking/writing.
        
        Scenario C: Other images:
        - Just chat about it like a friend.
        
        Tone: Friendly, Witty, Encouraging (Thai Language).
        Output: Plain text (No JSON needed here, just the reply string).
        """
        
        # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏á Gemini (Text + Image Bytes)
        image_part = {
            "mime_type": "image/jpeg",
            "data": image_bytes
        }
        
        # 4. ‡∏¢‡∏¥‡∏á‡πÑ‡∏õ‡∏´‡∏≤ Gemini
        response = chat_model.generate_content(
            [vision_prompt, image_part],
            safety_settings=safety_settings
        )
        
        ai_reply = response.text.strip()
        print(f"ü§ñ AI (Vision): {ai_reply}")
        
        # 5. ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö LINE
        line_bot_api.reply_message(reply_token, TextSendMessage(text=ai_reply))
        
    except Exception as e:
        print(f"Vision Error: {e}")
        line_bot_api.reply_message(reply_token, TextSendMessage(text="‡πÇ‡∏ó‡∏©‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô ‡πÄ‡∏ô‡πá‡∏ï‡πÑ‡∏°‡πà‡∏î‡∏µ ‡∏°‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÄ‡∏•‡∏¢ üòµ‚Äçüí´"))
